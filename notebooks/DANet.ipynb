{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchinfo import summary\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Local imports\n",
    "sys.path.append(\"/Users/leo/Desktop/Thesis/utils/\")\n",
    "sys.path.append(\"/Users/leo/Desktop/Thesis/models/\")\n",
    "\n",
    "from helper_functions import (delete_ds_store,plot_metrics,test,train,set_device,mean_std_finder,load_model)\n",
    "from DANet import _DANet\n",
    "from MBNV3 import MBNV3Creator\n",
    "from config import comet_token, project_name, workspace\n",
    "from torchvision.models import (mobilenet_v3_small, MobileNet_V3_Small_Weights as weights_small)\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prms = {\n",
    "    \"backbone\": mobilenet_v3_small,\n",
    "    \"weights\": None,\n",
    "    \"module\": _DANet,\n",
    "    \"module_alias\": \"DANet\",\n",
    "    \"data_path\": \"/Users/leo/Desktop/Thesis/data/vgg_200/\",\n",
    "    \"batch_size\": 32,\n",
    "    \"img_size\": 224,\n",
    "    \"num_classes\": 200,\n",
    "    \"epochs\": 50,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"device\": set_device(),\n",
    "    \"model\": None,\n",
    "    \"experiment\": Experiment(api_key=comet_token, project_name=project_name, workspace=workspace),\n",
    "    \"load_model\": False,\n",
    "}\n",
    "prms[\"model_save_path\"] = f\"./output/{prms['module_alias']}_{prms['data_path'].split('/')[-2]}.pth\"\n",
    "\n",
    "model = prms[\"model\"] = MBNV3Creator(prms[\"backbone\"], prms[\"num_classes\"], prms[\"weights\"], prms[\"device\"], prms[\"module\"])\n",
    "delete_ds_store(prms[\"data_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean, std = mean_std_finder(prms[\"data_path\"])\n",
    "mean, std = torch.tensor([0.5235, 0.4358, 0.3905]), torch.tensor([0.2993, 0.2770, 0.2729])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((prms[\"img_size\"], prms[\"img_size\"])),\n",
    "    transforms.RandAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((prms[\"img_size\"], prms[\"img_size\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing the data\n",
    "train_data = torchvision.datasets.ImageFolder(prms[\"data_path\"] + \"train/\", transform=train_transform)\n",
    "val_data = torchvision.datasets.ImageFolder(prms[\"data_path\"] + \"val/\", transform=test_transform)\n",
    "test_data = torchvision.datasets.ImageFolder(prms[\"data_path\"] + \"test/\", transform=test_transform)\n",
    "\n",
    "#Creating the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=prms[\"batch_size\"], shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=prms[\"batch_size\"], shuffle=False, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=prms[\"batch_size\"], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display random images from the dataset\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    #drop axis labels\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "model = load_model(model.build(), prms[\"model_save_path\"]) if prms[\"load_model\"] else model.build(set_all_trainable=True)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(prms[\"device\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=prms[\"learning_rate\"])\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "prms[\"experiment\"].log_parameters({\"loss\": criterion, \"optimizer\": optimizer}) if prms[\"experiment\"] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary = summary(model, input_size=(1, 3, prms[\"img_size\"], prms[\"img_size\"]),\n",
    "        col_names = [\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\", \"trainable\"],\n",
    "        col_width = 20,\n",
    "        row_settings = [\"var_names\"],\n",
    "        depth=8)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "prms[\"experiment\"].log_metric(\"total_params\", total_params) if prms[\"experiment\"] else None\n",
    "\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "train_losses, train_acc, val_losses, val_acc = train(model, train_loader, val_loader, criterion, optimizer, scheduler, hyper_params = prms, verbose = 2, test_transform = train_transform, experiment=prms[\"experiment\"])\n",
    "\n",
    "#plot the training and validation metrics\n",
    "plot_metrics(train_losses, train_acc, val_losses, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model\n",
    "test(model, test_loader, criterion, hyper_params = prms, experiment = prms[\"experiment\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
