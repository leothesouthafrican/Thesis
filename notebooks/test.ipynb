{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('/Users/leo/Desktop/Thesis/models/')\n",
    "from SE_weight_module import SEWeightModule\n",
    "\n",
    "def conv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1, groups=1):\n",
    "    \"\"\"standard convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                    padding=padding, dilation=dilation, groups=groups, bias=False)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class PSAModule(nn.Module):\n",
    "    def __init__(self, inplans, planes, conv_kernels=[3, 5, 7, 9], stride=1, conv_groups=[1, 4, 8, 16]):\n",
    "        super(PSAModule, self).__init__()\n",
    "        self.conv_1 = conv(inplans, planes//4, kernel_size=conv_kernels[0], padding=conv_kernels[0]//2,\n",
    "                            stride=stride, groups=conv_groups[0])\n",
    "        self.conv_2 = conv(inplans, planes//4, kernel_size=conv_kernels[1], padding=conv_kernels[1]//2,\n",
    "                            stride=stride, groups=conv_groups[1])\n",
    "        self.conv_3 = conv(inplans, planes//4, kernel_size=conv_kernels[2], padding=conv_kernels[2]//2,\n",
    "                            stride=stride, groups=conv_groups[2])\n",
    "        self.conv_4 = conv(inplans, planes//4, kernel_size=conv_kernels[3], padding=conv_kernels[3]//2,\n",
    "                            stride=stride, groups=conv_groups[3])\n",
    "        self.se = SEWeightModule(planes // 4)\n",
    "        self.split_channel = planes // 4\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #pyramid convolutions \n",
    "        batch_size = x.shape[0]\n",
    "        x1 = self.conv_1(x) \n",
    "        x2 = self.conv_2(x)\n",
    "        x3 = self.conv_3(x)\n",
    "        x4 = self.conv_4(x)\n",
    "\n",
    "        feats = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "        feats = feats.view(batch_size, 4, self.split_channel, feats.shape[2], feats.shape[3])\n",
    "\n",
    "        x1_se = self.se(x1)\n",
    "        x2_se = self.se(x2)\n",
    "        x3_se = self.se(x3)\n",
    "        x4_se = self.se(x4)\n",
    "\n",
    "        x_se = torch.cat((x1_se, x2_se, x3_se, x4_se), dim=1)\n",
    "        attention_vectors = x_se.view(batch_size, 4, self.split_channel, 1, 1)\n",
    "        attention_vectors = self.softmax(attention_vectors)\n",
    "        feats_weight = feats * attention_vectors\n",
    "        for i in range(4):\n",
    "            x_se_weight_fp = feats_weight[:, i, :, :]\n",
    "            if i == 0:\n",
    "                out = x_se_weight_fp\n",
    "            else:\n",
    "                out = torch.cat((x_se_weight_fp, out), 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
